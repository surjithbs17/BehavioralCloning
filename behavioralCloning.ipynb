{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pathlib import PurePosixPath\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "cameras = ['left', 'center', 'right']\n",
    "camera_center = ['center']\n",
    "steering_offset = {'left': 0.25, 'center': 0., 'right': -.25}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NVIDIA MODEL Uses YUV, Lets try YUV\n",
    "def load_image(path, filename):\n",
    "    filename = filename.strip()\n",
    "    if filename.startswith('IMG'):\n",
    "        filename = path+'/'+filename\n",
    "    else:\n",
    "        filename = path+'/IMG/'+PurePosixPath(filename).name\n",
    "    img = cv2.imread(filename)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "def randomise_image_brightness(image):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_YUV2BGR)\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_BGR2HSV)\n",
    "    bv = .25 + np.random.uniform()\n",
    "    hsv[::2] = hsv[::2]*bv\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    yuv = cv2.cvtColor(rgb, cv2.COLOR_BGR2YUV)\n",
    "    return yuv\n",
    "\n",
    "def crop_camera(img, crop_height=66, crop_width=200):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    y_start = 60\n",
    "    x_start = int(width/2)-int(crop_width/2)\n",
    "    return img[y_start:y_start+crop_height, x_start:x_start+crop_width]\n",
    "\n",
    "def jitter_image_rotation(image, steering):\n",
    "    rows, cols, _ = image.shape\n",
    "    transRange = 100\n",
    "    numPixels = 10\n",
    "    valPixels = 0.4\n",
    "    transX = transRange * np.random.uniform() - transRange/2\n",
    "    steering = steering + transX/transRange * 2 * valPixels\n",
    "    transY = numPixels * np.random.uniform() - numPixels/2\n",
    "    transMat = np.float32([[1, 0, transX], [0, 1, transY]])\n",
    "    image = cv2.warpAffine(image, transMat, (cols, rows))\n",
    "    return image, steering\n",
    "\n",
    "def jitter_camera_image(row, log_path, cameras):\n",
    "    steering = getattr(row, 'steering')\n",
    "\n",
    "    # use one of the cameras randomily\n",
    "    camera = cameras[random.randint(0, len(cameras)-1)]\n",
    "    steering += steering_offset[camera]\n",
    "\n",
    "    image = load_image(log_path, getattr(row, camera))\n",
    "    image, steering = jitter_image_rotation(image, steering)\n",
    "    image = randomise_image_brightness(image)\n",
    "\n",
    "    return image, steering\n",
    "\n",
    "def gen_train_data(path='./data', log_file='driving_log.csv', skiprows=1,\n",
    "                   cameras=cameras, batch_size=128):\n",
    "\n",
    "    # load the csv log file\n",
    "    print(\"Cameras: \", cameras)\n",
    "    print(\"Log path: \", path)\n",
    "    print(\"Log file: \", log_file)\n",
    "\n",
    "    column_names = ['center', 'left', 'right',\n",
    "                    'steering', 'throttle', 'brake', 'speed']\n",
    "    data_df = pd.read_csv(path+'/'+log_file,\n",
    "                          names=column_names, skiprows=skiprows)\n",
    "    data_count = len(data_df)\n",
    "\n",
    "    print(\"Data in Log, %d rows.\" % (len(data_df)))\n",
    "\n",
    "    while True:\n",
    "        features = []\n",
    "        labels = []\n",
    "        #Choosing random samples  \n",
    "        \n",
    "        while len(features) < batch_size:\n",
    "            row = data_df.iloc[np.random.randint(data_count-1)]\n",
    "\n",
    "            image, steering = jitter_camera_image(row, path, cameras)\n",
    "\n",
    "            if random.random() >= .5 and abs(steering) > 0.1:\n",
    "                image = cv2.flip(image, 1)\n",
    "                steering = -steering\n",
    "\n",
    "            image = crop_camera(image)\n",
    "            features.append(image)\n",
    "            labels.append(steering)\n",
    "\n",
    "        # yield the batch\n",
    "        yield (np.array(features), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_nvidia_model(img_height=66, img_width=200, img_channels=3,\n",
    "                       dropout=.5):\n",
    "\n",
    "    # build sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # normalisation layer\n",
    "    img_shape = (img_height, img_width, img_channels)\n",
    "    model.add(Lambda(lambda x: x * 1./127.5 - 1,\n",
    "                     input_shape=(img_shape),\n",
    "                     output_shape=(img_shape), name='Normalization'))\n",
    "\n",
    "    # convolution layers with dropout\n",
    "    nb_filters = [24, 36, 48, 64, 64]\n",
    "    kernel_size = [(5, 5), (5, 5), (5, 5), (3, 3), (3, 3)]\n",
    "    same, valid = ('same', 'valid')\n",
    "    padding = [valid, valid, valid, valid, valid]\n",
    "    strides = [(2, 2), (2, 2), (2, 2), (1, 1), (1, 1)]\n",
    "\n",
    "    for l in range(len(nb_filters)):\n",
    "        model.add(Convolution2D(nb_filters[l],\n",
    "                                kernel_size[l][0], kernel_size[l][1],\n",
    "                                border_mode=padding[l],\n",
    "                                subsample=strides[l],\n",
    "                                activation='elu'))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    # flatten layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # fully connected layers with dropout\n",
    "    neurons = [100, 50, 10]\n",
    "    for l in range(len(neurons)):\n",
    "        model.add(Dense(neurons[l], activation='elu'))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    # logit output - steering angle\n",
    "    model.add(Dense(1, activation='elu', name='Out'))\n",
    "\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(_):\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "    dropout = 0.55\n",
    "    data_dir = \"./longdata\"\n",
    "    validation_dir = \"./udacity_data\"\n",
    "    train_log = pd.read_csv(data_dir+\"/driving_log.csv\")\n",
    "    train_size = train_log.shape[0]\n",
    "    valid_log = pd.read_csv(data_dir+\"/driving_log.csv\")\n",
    "    valid_size = valid_log.shape[0]\n",
    "    # build model and display layers\n",
    "    model = build_nvidia_model(dropout=dropout)\n",
    "    for l in model.layers:\n",
    "        print(l.name, l.input_shape, l.output_shape,\n",
    "        l.activation if hasattr(l, 'activation') else 'none')\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    plot(model, to_file='model.png', show_shapes=True)\n",
    "    #load previous trained model\n",
    "    model.load_weights(\"model.h5\")\n",
    "    model.fit_generator(\n",
    "        gen_train_data(path=data_dir,\n",
    "                       cameras=cameras,\n",
    "                       batch_size=batch_size\n",
    "                       ),\n",
    "        samples_per_epoch=train_size,\n",
    "        nb_epoch=epochs,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                                  patience=1, verbose=1, mode='auto')],\n",
    "        validation_data=gen_train_data(path=validation_dir,\n",
    "                                     batch_size=batch_size),\n",
    "        nb_val_samples=valid_size)\n",
    "\n",
    "    # save weights and model\n",
    "    model.save_weights('model.h5')\n",
    "    with open('model.json', 'w') as modelfile:\n",
    "        json.dump(model.to_json(), modelfile)\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
